'use client'

import { useState, useEffect, useCallback } from 'react'
import * as faceapi from 'face-api.js'

interface FaceDetection {
  detection: faceapi.FaceDetection
  descriptor?: Float32Array
}

interface UseFaceRecognitionReturn {
  modelsLoaded: boolean
  isLoading: boolean
  error: string | null
  detectFace: (image: HTMLImageElement | HTMLVideoElement | HTMLCanvasElement) => Promise<FaceDetection | null>
  extractDescriptor: (image: HTMLImageElement | HTMLVideoElement | HTMLCanvasElement) => Promise<Float32Array | null>
  calculateSimilarity: (desc1: Float32Array, desc2: Float32Array) => number
}

export function useFaceRecognition(): UseFaceRecognitionReturn {
  const [modelsLoaded, setModelsLoaded] = useState(false)
  const [isLoading, setIsLoading] = useState(true)
  const [error, setError] = useState<string | null>(null)

  // Cargar modelos de face-api.js
  useEffect(() => {
    const loadModels = async () => {
      try {
        setIsLoading(true)
        setError(null)

        // Los modelos deben estar en la carpeta public/models
        // En Next.js, los archivos en public/ se sirven desde la ra√≠z
        const MODEL_URL = '/models'

        console.log('üîÑ Cargando modelos de reconocimiento facial desde:', MODEL_URL)
        console.log('üìç Verificando que los modelos existan...')

        // Verificar que los modelos existan antes de cargarlos
        try {
          const response = await fetch(`${MODEL_URL}/tiny_face_detector_model-weights_manifest.json`)
          if (!response.ok) {
            throw new Error(`No se encontraron los modelos en ${MODEL_URL}. Ejecuta: npm run download-face-models`)
          }
          console.log('‚úÖ Modelos encontrados en el servidor')
        } catch (fetchError) {
          console.error('‚ùå Error verificando modelos:', fetchError)
          throw new Error(`No se pueden acceder a los modelos desde ${MODEL_URL}. Aseg√∫rate de que est√©n en public/models/`)
        }

        console.log('üì¶ Cargando modelos de TensorFlow.js...')
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
          faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
          faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
          faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
        ])

        console.log('‚úÖ Todos los modelos cargados exitosamente')

        setModelsLoaded(true)
        console.log('‚úÖ Modelos de reconocimiento facial cargados correctamente')
      } catch (err: any) {
        console.error('‚ùå Error cargando modelos de reconocimiento facial:', err)
        const errorMessage = err?.message || 'Error desconocido'
        console.error('Detalles del error:', errorMessage)
        
        // Mensaje de error m√°s descriptivo
        let userMessage = 'Error al cargar los modelos de reconocimiento facial. '
        if (errorMessage.includes('404') || errorMessage.includes('Not Found')) {
          userMessage += 'Los modelos no se encontraron en /public/models. Ejecuta: npm run download-face-models'
        } else if (errorMessage.includes('CORS')) {
          userMessage += 'Error de CORS. Verifica que los modelos est√©n en public/models/'
        } else {
          userMessage += `Error: ${errorMessage}. Verifica que los modelos est√©n en /public/models`
        }
        
        setError(userMessage)
      } finally {
        setIsLoading(false)
      }
    }

    loadModels()
  }, [])

  // Detectar rostro en una imagen
  const detectFace = useCallback(async (
    image: HTMLImageElement | HTMLVideoElement | HTMLCanvasElement
  ): Promise<FaceDetection | null> => {
    if (!modelsLoaded) {
      throw new Error('Los modelos no est√°n cargados a√∫n')
    }

    try {
      // Validar que la imagen tenga dimensiones v√°lidas
      if (!image || (image instanceof HTMLImageElement && (!image.width || !image.height))) {
        return null
      }

      // Detectar rostro con el modelo tinyFaceDetector (m√°s r√°pido)
      const detection = await faceapi
        .detectSingleFace(image, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor()

      if (!detection || !detection.detection || !detection.descriptor) {
        return null
      }

      // Validar que la caja de detecci√≥n tenga valores v√°lidos
      const box = detection.detection.box
      if (!box || 
          box.x === null || box.x === undefined || 
          box.y === null || box.y === undefined || 
          box.width === null || box.width === undefined || 
          box.height === null || box.height === undefined ||
          box.width <= 0 || box.height <= 0) {
        console.warn('‚ö†Ô∏è Detecci√≥n con valores inv√°lidos, ignorando...', box)
        return null
      }

      return {
        detection: detection.detection,
        descriptor: detection.descriptor as Float32Array
      }
    } catch (err) {
      console.error('Error detectando rostro:', err)
      return null
    }
  }, [modelsLoaded])

  // Extraer descriptor facial
  const extractDescriptor = useCallback(async (
    image: HTMLImageElement | HTMLVideoElement | HTMLCanvasElement
  ): Promise<Float32Array | null> => {
    if (!modelsLoaded) {
      throw new Error('Los modelos no est√°n cargados a√∫n')
    }

    try {
      // Validar que la imagen tenga dimensiones v√°lidas
      if (!image || (image instanceof HTMLImageElement && (!image.width || !image.height))) {
        return null
      }

      // Usar detectSingleFace con validaci√≥n m√°s estricta
      const detection = await faceapi
        .detectSingleFace(image, new faceapi.TinyFaceDetectorOptions({
          inputSize: 320, // Tama√±o de entrada m√°s grande para mejor precisi√≥n
          scoreThreshold: 0.5 // Umbral de confianza m√°s alto
        }))
        .withFaceLandmarks()
        .withFaceDescriptor()

      if (!detection) {
        return null
      }

      // Validar que la detecci√≥n tenga todos los componentes necesarios
      if (!detection.detection || !detection.descriptor) {
        return null
      }

      // Validar que la caja de detecci√≥n tenga valores v√°lidos ANTES de usarla
      const box = detection.detection.box
      if (!box || 
          typeof box.x !== 'number' || isNaN(box.x) ||
          typeof box.y !== 'number' || isNaN(box.y) ||
          typeof box.width !== 'number' || isNaN(box.width) ||
          typeof box.height !== 'number' || isNaN(box.height) ||
          box.width <= 0 || box.height <= 0 ||
          box.x < 0 || box.y < 0) {
        console.warn('‚ö†Ô∏è Detecci√≥n con valores inv√°lidos al extraer descriptor, ignorando...', {
          x: box?.x,
          y: box?.y,
          width: box?.width,
          height: box?.height
        })
        return null
      }

      // Validar que el descriptor sea v√°lido
      if (!(detection.descriptor instanceof Float32Array) || detection.descriptor.length !== 128) {
        console.warn('‚ö†Ô∏è Descriptor inv√°lido:', {
          type: detection.descriptor?.constructor?.name,
          length: detection.descriptor?.length
        })
        return null
      }

      return detection.descriptor as Float32Array
    } catch (err) {
      console.error('Error extrayendo descriptor:', err)
      return null
    }
  }, [modelsLoaded])

  // Calcular similitud entre dos descriptores (distancia euclidiana)
  const calculateSimilarity = useCallback((desc1: Float32Array, desc2: Float32Array): number => {
    if (desc1.length !== desc2.length) {
      return 0
    }

    // Calcular distancia euclidiana
    let sum = 0
    for (let i = 0; i < desc1.length; i++) {
      const diff = desc1[i] - desc2[i]
      sum += diff * diff
    }
    const distance = Math.sqrt(sum)

    // Convertir distancia a similitud (0-1, donde 1 es id√©ntico)
    // face-api.js: distancia < 0.6 = mismo rostro, distancia >= 0.6 = diferente rostro
    // Usamos una funci√≥n que mapea:
    // - distance = 0 ‚Üí similarity = 1.0 (id√©ntico)
    // - distance = 0.6 ‚Üí similarity ‚âà 0.5 (l√≠mite)
    // - distance > 0.6 ‚Üí similarity < 0.5 (diferente)
    // F√≥rmula mejorada: usar una curva m√°s suave
    const threshold = 0.6 // Umbral de face-api.js
    const maxDistance = 1.2 // Distancia m√°xima esperada
    
    // Normalizaci√≥n mejorada: distancia peque√±a = alta similitud
    let similarity: number
    if (distance <= threshold) {
      // Para distancias peque√±as (mismo rostro), similitud alta
      similarity = 1 - (distance / threshold) * 0.5 // 0.6 ‚Üí 0.5, 0 ‚Üí 1.0
    } else {
      // Para distancias grandes (diferente rostro), similitud baja
      similarity = 0.5 * (1 - (distance - threshold) / (maxDistance - threshold))
      similarity = Math.max(0, similarity)
    }
    
    return similarity
  }, [])

  return {
    modelsLoaded,
    isLoading,
    error,
    detectFace,
    extractDescriptor,
    calculateSimilarity
  }
}

